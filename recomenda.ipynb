{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import gc, math, warnings, time\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stats\n",
    "from scipy import stats\n",
    "import ppscore as pps\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "# Estebelece limites para visualização no notebook\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',500)\n",
    "\n",
    "# Limita a 3 casas decimais a apresentação das variaveis tipo float\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de dados do arquivo CSV básico e análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados do arquivo\n",
    "df_blk = pd.read_csv('../temp/vmblacklist.csv', sep=';')  # Lista de máquinas que não devem ser ajustadas\n",
    "df = pd.read_csv('../temp/vm_list.csv', sep=';', parse_dates=['timestamp'])  # Lista total de VMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define periodo de análise em dias e remove medições do dia de hoje\n",
    "periodo = 7\n",
    "\n",
    "#Define variaveis e datasets cmo preparação para execução da rotina de análise\n",
    "cols = ['vmname', 'weekday', 'minimo', 'maximo', 'media', '50%', '95%']\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekDays = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\", 4:\"Friday\", 5: \"Saturday\", 6:\"Sunday\"}\n",
    "ordem = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "fileout= '../fig/{}.jpg'\n",
    "    \n",
    "# Cria dataframe para armazenamento de dados estatísticos\n",
    "df_data = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove máquinas da black list da amostra\n",
    "dfx = df[df['vmname'].isin(df_blk['vmname']) == False]\n",
    "\n",
    "# Filtra amostra de dados para o periodo de 7 dias contados a partir do dia anterior à ultima data armazenada.\n",
    "# Isso garante dias completos\n",
    "end_date = dfx['timestamp'].max()\n",
    "\n",
    "# Calcula data final da amostra - 1 dia antes da data da últime medição\n",
    "end_date = end_date - timedelta(1)\n",
    "\n",
    "# Ajusta horário para final do dia\n",
    "end_date = end_date.strftime('%Y-%m-%d') + ' 23:59:59'\n",
    "\n",
    "# Converte novamente para o formato datetime\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Calcula data inicial da amostra = 7 dias antes da data final\n",
    "initial_date = (pd.to_datetime(end_date.strftime('%Y-%m-%d') + ' 00:00:00')) - timedelta(periodo-1)\n",
    "\n",
    "dfx = dfx[(dfx['timestamp'] > initial_date) & (dfx['timestamp'] <= end_date)]\n",
    "\n",
    "\n",
    "# Garante que o campo timestamp está no formato de datetime\n",
    "dfx['timestamp'] = pd.to_datetime(dfx['timestamp']) \n",
    "\n",
    "# Ordena registros\n",
    "dfx.sort_values(by=['timestamp'], inplace=True)\n",
    "\n",
    "vm_list = list(dfx['vmname'].unique())\n",
    "\n",
    "# Seta definições de tamanho para apresentação de gráficos\n",
    "f, ax = plt.subplots(nrows=3, ncols=4)\n",
    "plt.rcParams['figure.figsize'] = [17, 18]\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.17)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for vms in vm_list:\n",
    "    # ETAPA 1 ===========================================\n",
    "    # Filtra base de dados para conter somente registros relacionados às VMs selecionadas\n",
    "    df_aux1 = dfx[dfx['vmname'] == vms]\n",
    "\n",
    "    # Reorganiza indices\n",
    "    df_aux1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Define coluna timestamp como indice\n",
    "    df_aux1.set_index(['timestamp'], inplace=True)\n",
    "    \n",
    "    # ETAPA 2 ===========================================\n",
    "    # Fazendo resample dos registros considerando consolidações a cada 1 minuto\n",
    "    df_aux1 = df_aux1.resample('1min').mean()\n",
    "\n",
    "    # Preenche valores faltantes utilizando KNN\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    df_aux2 = imputer.fit_transform(df_aux1)\n",
    "    # Remontando dataframe\n",
    "    df_aux1 = pd.DataFrame(df_aux2, index=df_aux1.index, columns=df_aux1.columns)\n",
    "    del df_aux2\n",
    "    gc.collect();\n",
    "    \n",
    "    # Adiciona novas colunas para gráficos e ajusta base para apresentação em determinados tipos de gráficos\n",
    "    df_aux2 = df_aux1.copy()\n",
    "    df_aux2['weekday'] = df_aux2.index.weekday\n",
    "    df_aux2['weekday'] = df_aux2['weekday'].map(weekDays)\n",
    "    \n",
    "    # ETAPA 3 - Gráficos ================================\n",
    "    f, ax = plt.subplots(nrows=3, ncols=4)\n",
    "    plt.rcParams['figure.figsize'] = [17, 18]\n",
    "    plt.subplots_adjust(wspace=0.15, hspace=0.17)\n",
    "\n",
    "    ax1 = plt.subplot2grid((3, 4), (0, 0), colspan=4, rowspan=1)\n",
    "    ax2 = plt.subplot2grid((3, 4), (1, 0))\n",
    "    ax3 = plt.subplot2grid((3, 4), (1, 1))\n",
    "    ax4 = plt.subplot2grid((3, 4), (1, 2), colspan=2, rowspan=1)\n",
    "    ax5 = plt.subplot2grid((3, 4), (2, 0), colspan=4, rowspan=1)\n",
    "\n",
    "    # Gráfico 1 - Linha\n",
    "    sns.lineplot(data = df_aux1, x=df_aux1.index, y=df_aux1.cpu, ax=ax1)\n",
    "    ax1.grid(color='lightgray', linestyle='-', linewidth=0.2)\n",
    "    ax1.set_title(vms + ' - Período de 7 dias: ' + initial_date.strftime('%d/%m/%Y %H:%M') + \\\n",
    "                  ' a ' + end_date.strftime('%d/%m/%Y %H:%M'), fontsize=14)\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('% de consumo de CPU', fontsize=12)\n",
    "\n",
    "    # Gráfico 2 - Histograma básico\n",
    "    df_aux1['cpu'].hist(bins = 30, ax = ax2)\n",
    "    ax2.set_title('% de consumo de CPU', fontsize=12)\n",
    "    \n",
    "    # Gráfico 3- Histograma com curva normal\n",
    "    #if df_aux1['cpu'].max() != 0:\n",
    "    if len(df_aux1['cpu'].unique()) > 1:\n",
    "        sns.distplot(df_aux1['cpu'], ax = ax3, fit=norm)\n",
    "        ax3.set_title('% de consumo de CPU', fontsize=12)\n",
    "        ax3.set_xlabel('')\n",
    "    \n",
    "    # Gráfico 4 - Boxplot\n",
    "    sns.boxplot(x='weekday', y='cpu', data=df_aux2, ax = ax4, orient=\"v\", order=ordem, palette=\"Set2\")\n",
    "    ax4.set_title('% de consumo de CPU por dia da semana', fontsize=12)\n",
    "    ax4.set_xlabel('')\n",
    "    ax4.set_ylabel('')\n",
    "    \n",
    "    \n",
    "    # ETAPA 4 - Métricas estatisticas ===================\n",
    "    # Popula dataframe auxiliar com dados estatísticos das metricas dos dias da semana\n",
    "    df_aux3 = df_aux2.groupby(['weekday']).describe(percentiles=[0.95]).reset_index().round(decimals=3)\n",
    "        \n",
    "    # remove colunas indesejadas e estrutura multiindex e renomeia colunas\n",
    "    df_aux3.drop('count', axis=1, level= 1, inplace=True)\n",
    "    df_aux3.columns = [''.join(col).strip() for col in df_aux3.columns.values]\n",
    "    df_aux3.rename(columns = {'cpumean':'media', 'cpustd': 'desvio', 'cpumin': 'minimo', \n",
    "                             'cpumax': 'maximo', 'cpu50%': '50%', 'cpu95%': '95%'}, inplace = True)\n",
    "    df_aux3['vmname'] = vms\n",
    "   \n",
    "    #Cria coluna adicional para 3sigma (linha de corte para análise de redução)\n",
    "    df_aux3['3sigma'] = 3 * df_aux3['desvio'] + df_aux3['media']\n",
    "        \n",
    "    # Cria dataframe auxiliar com indicadores estatísticos de todo o periodo\n",
    "    df_aux1 = df_aux2.describe(percentiles=[0.95]).reset_index().round(decimals=3)\n",
    "    df_aux1 = df_aux1.T.reset_index()\n",
    "    header_row = 0\n",
    "    df_aux1.columns = df_aux1.iloc[header_row]\n",
    "    \n",
    "    # Remove colunas e linhas desnecessárias e renomeia colunas\n",
    "    df_aux1.drop(['index', 'count'], axis=1, inplace=True)\n",
    "    df_aux1.drop(0, axis=0, inplace=True)\n",
    "    df_aux1.rename(columns = {'mean':'media', 'std': 'desvio', 'min': 'minimo', \n",
    "                              'max': 'maximo', '50%': '50%', '95%': '95%'}, inplace = True)\n",
    "    df_aux1['vmname'] = vms\n",
    "    df_aux1['weekday']= 'AllDays'\n",
    "    \n",
    "    #Cria coluna adicional para 3sigma (linha de corte para análise de redução)\n",
    "    df_aux1['3sigma'] = 3 * df_aux1['desvio'] + df_aux1['media']\n",
    "\n",
    "    # Acrescenta dados da metrica na base de estatísticas\n",
    "    df_aux2 = pd.concat([df_aux1, df_aux3], ignore_index=True)\n",
    "    df_aux2.drop(['vmname'], axis=1, inplace=True)\n",
    "    df_aux2 = df_aux2[['weekday', 'minimo', 'maximo', 'media', 'desvio', '50%', '95%', '3sigma']]\n",
    "    \n",
    "    # Converte variaveis numéricas para formato float e arredonda em 3 casas decimais\n",
    "    for col in df_aux2.columns[1:]:\n",
    "        df_aux2[col] = df_aux2[col].astype('float')\n",
    "        df_aux2[col] = df_aux2[col].round(decimals=3)\n",
    "    \n",
    "    df_aux2['3sigma'] = df_aux2['3sigma'].round(decimals=0)\n",
    "    df_data = pd.concat([df_data, df_aux1, df_aux3], ignore_index=True)\n",
    "       \n",
    "\n",
    "    # Grafico 5 - Tabela com dados\n",
    "    ax5.xaxis.set_visible(False)  \n",
    "    ax5.yaxis.set_visible(False)  \n",
    "    ax5.set_frame_on(False)  \n",
    "    tabla = table(ax5, df_aux2, loc='upper right', colWidths=[0.07]*len(df_aux2.columns))  \n",
    "    tabla.auto_set_font_size(False) \n",
    "    tabla.set_fontsize(12) \n",
    "    tabla.scale(1.7, 1.2) \n",
    "    \n",
    "    # Salva gráfico em arquivo jpg\n",
    "    plt.savefig(fileout.format(vms), format='jpg')\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "\n",
    "# Ajustando colunas da base e arredondando resultados numericos \n",
    "df_data = df_data[['vmname', 'weekday', 'minimo', 'maximo', 'media', 'desvio', '50%', '95%', '3sigma']]\n",
    "for col in df_data.columns[2:]:\n",
    "    df_data[col] = df_data[col].astype('float')\n",
    "    df_data[col] = df_data[col].round(decimals=3)\n",
    "\n",
    "df_data['3sigma'] = df_data['3sigma'].round(decimals=0)\n",
    "\n",
    "# Gravando arquivo final\n",
    "df_data.to_csv('../temp/estatisticas.csv', sep=';', decimal=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adicionando informação à tabela de estatisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados dos arquivos\n",
    "# Carrega arquivo csv com lista de tamanhos, renomeia coluna e seleciona as que interessam para montar dataframe\n",
    "df_vms = pd.read_csv('../temp/geral.csv', sep=';')              # Lista de VMs \n",
    "df_est = pd.read_csv('../temp/estatisticas.csv', sep=';', decimal=',')   # Estatísticas das VMs\n",
    "cols = ['vmsize', 'cpu', 'ram_gb', 'serie', 'order']\n",
    "df_tam = pd.read_csv('../temp/tamanhos.csv', sep=';', header=0, names=cols, usecols=cols)  # Catálogo de series e tamanhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantem em df_est somente registros do consolidado da semana (AllDays)\n",
    "df_est.drop(df_est[df_est['weekday']!='AllDays'].index, axis=0, inplace=True)\n",
    "\n",
    "# Mantem em df_vms somente registros de servidores que existam na base de estatisticas\n",
    "df_vms = df_vms[df_vms['vmname'].isin(df_est['vmname']) == True]\n",
    "\n",
    "# Ajusta tamanhos de ram para escala em GB\n",
    "df_tam['ram_gb'] /= 1024\n",
    "df_tam['ram_gb'].round(2)\n",
    "\n",
    "# Ordena df_tam por vmsize e cpu\n",
    "df_tam.sort_values(by=['serie', 'order'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Faz merge das tabelas df_est e df_vms\n",
    "df_est = df_est.merge(df_vms, how='right', left_on='vmname', right_on='vmname')\n",
    "\n",
    "# Faz merge das tabelas df_est e df_tam\n",
    "df_est = df_est.merge(df_tam, how='left', left_on='vmsize', right_on='vmsize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove da lista servidores com 1 cpu e com 3sigma maior que 40% ou 3sigma igual a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est.drop(df_est[df_est['cpu'] == 1.0].index, axis = 0, inplace=True)\n",
    "df_est.drop(df_est[(df_est['3sigma'] > 35.0) | (df_est['3sigma'] == 0.0)].index, axis = 0, inplace=True)\n",
    "\n",
    "# Ordena lista por vmsize, cpu, ram e nome\n",
    "df_est.sort_values(by=['3sigma', 'serie', 'order'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captura métricas atuais e analisa opções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara df_est para novos dados\n",
    "cols = ['new_vmsize', 'new_cpu', 'new_ram_gb', 'new_3sigma']\n",
    "df_est[cols] = ['', 0.0, 0.0, 0.0]\n",
    "\n",
    "# Indexa tabela df_est pelo vmname\n",
    "df_est.set_index(['vmname'], inplace=True)\n",
    "\n",
    "# Ordena base de tamanhos de forma decrescente\n",
    "df_tam.sort_values(by=['serie', 'order', 'vmsize'], ascending=False, ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for vms in df_est.index:\n",
    "    # Seleciona dados atuais do servidor em análise\n",
    "    cpu_atual = df_est.loc[vms, 'cpu']\n",
    "    ram_atual = df_est.loc[vms, 'ram_gb']\n",
    "    serie_atual = df_est.loc[vms, 'serie']\n",
    "    order_atual = df_est.loc[vms, 'order']\n",
    "    sigma_atual = df_est.loc[vms, '3sigma']\n",
    "\n",
    "    cpu_new = 0\n",
    "    sigma_new = 0\n",
    "    vmsize_new = ''\n",
    "    \n",
    "    # Separa em df_tam conjunto de tamanhos da mesma serie mas com número de ordem inferior ao atual\n",
    "    df = df_tam[(df_tam['serie']==serie_atual) & (df_tam['order']<=(order_atual-1))].reset_index(drop=True)\n",
    "    \n",
    "    # Analisa informações de vms e busca por servidor com tamanho menor\n",
    "    for key, value in enumerate(df['vmsize']):\n",
    "        cpu = df.loc[key, 'cpu']\n",
    "        ram = df.loc[key, 'ram_gb']\n",
    "        if (cpu < cpu_atual) and (ram >= ram_atual/2):\n",
    "            cpu_new = cpu\n",
    "            vmsize_new = df.loc[key, 'vmsize']\n",
    "            sigma_new = (cpu_atual * sigma_atual / cpu_new) * 1.10\n",
    "            break\n",
    "\n",
    "    if cpu_new != 0:\n",
    "        # Complementa informações em tabela de estatísticas df_est\n",
    "        df_est.loc[vms, 'new_vmsize'] = vmsize_new\n",
    "        df_est.loc[vms, 'new_cpu'] = cpu_new\n",
    "        df_est.loc[vms, 'new_ram_gb'] = ram\n",
    "        df_est.loc[vms, 'new_3sigma'] = sigma_new\n",
    "    else:\n",
    "        # Não foi encontrada nenhuma máquina dentro da mesma serie que atenda aos requisitos de redução\n",
    "        df_est.loc[vms, 'new_vmsize'] = 'NA'\n",
    "        df_est.loc[vms, 'new_cpu'] = 0\n",
    "        df_est.loc[vms, 'new_ram_gb'] = 0\n",
    "        df_est.loc[vms, 'new_3sigma'] = 0\n",
    "\n",
    "# Ajustando valores e apresentação final\n",
    "df = df_est.drop(df_est[df_est['new_vmsize']=='NA'].index, axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "df.sort_values(by=['vmname'], ignore_index=True, inplace=True)\n",
    "\n",
    "df.round(decimals=3)\n",
    "df['new_cpu'] = df['new_cpu'].astype('int32')\n",
    "df['new_3sigma'] = df['new_3sigma'].round(decimals=0)\n",
    "df.drop(['order'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grava arquivo de recomendações \n",
    "df.to_excel('../data/recomenda.xlsx', float_format=\"%7.3f\", sheet_name='Recomendações', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "392px",
    "left": "886px",
    "right": "20px",
    "top": "77px",
    "width": "403px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
